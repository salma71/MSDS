---
title: "Chapter 8 - Introduction to Linear Regression HomeWork_8"
author: "Salma Elshahawy"
output:
    pdf_document:
        extra_dependencies: ["geometry", "multicol", "multirow", "xcolor"]
        latex_engine: xelatex
        keep_tex:  true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Nutrition at Starbucks, Part I.** (8.22, p. 326) The scatterplot below shows the relationship between the number of calories and amount of carbohydrates (in grams) Starbucks food menu items contain. Since Starbucks only lists the number of calories on the display items, we are interested in predicting the amount of carbs a menu item has based on its calorie content.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="33%", fig.height=4}
library(openintro)
# load data ---------------------------------------------------------
starbucks <- read.csv("https://github.com/jbryer/DATA606Fall2019/raw/master/course_data/starbucks.csv")
# model calories vs. carbos -----------------------------------------
m_carb_cals <- lm(carb ~ calories, data = starbucks)
# plot calories vs. carbos ------------------------------------------
par(mar = c(3.5, 4, 1, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
plot(carb ~ calories, data = starbucks, 
     pch = 19, col = COL[1,2], 
     xlab = "Calories", ylab = "Carbs (grams)", axes = FALSE)
axis(1)
axis(2, at = seq(20, 80, 20))
box()
abline(m_carb_cals, col = COL[2], lwd = 2)
# plot residuals ----------------------------------------------------
par(mar = c(3.5, 4, 1, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)

plot(m_carb_cals$residuals ~ starbucks$calories,
     xlab = "Calories", ylab = "Residuals", 
     col = COL[1,2], pch = 19,
     ylim = c(-30, 30), axes = FALSE)
axis(1)
axis(2, at = seq(-20, 20, 20))
box()
abline(h = 0, lty = 2)
# histogram of residuals --------------------------------------------
par(mar = c(3.5, 2.5, 0.5, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)

hist(m_carb_cals$residuals,
     col = COL[1], 
     xlab = "Residuals", ylab = "", main = "", 
     axes = FALSE, xlim = c(-40,40))
axis(1, at = seq(-40, 40, 20))
axis(2)
```

(a) Describe the relationship between number of calories and amount of carbohydrates (in grams) that Starbucks food menu items contain.

  _The relationship between calories and amount of carbo seems to be linear but not strong_

(b) In this scenario, what are the explanatory and response variables?

  _The explanatory is Calories, and the response variable is Carbs_
  
(c) Why might we want to fit a regression line to these data?

  _We need to do that to have a prediction of the amount of Carbs in the response variable_

(d) Do these data meet the conditions required for fitting a least squares line?

  _Linearity = > yes, it follows a normal distribution according to histogram_
  _Nearly normal residuals => faily yes;however the histogram is not symmetrical, this may opt out this condition_
  _Constant Variability => The variablility is not constant, where there are more residuals on the rightside of the scatter plot_
  _I don't think  that this model can fit the regression model due to lack of variance and unsymmetrical residuals_


--------------------------------------------------------------------------------

\clearpage

**Body measurements, Part I.** (8.13, p. 316) Researchers studying anthropometry collected body girth measurements and skeletal diameter measurements, as well as age, weight, height and gender for 507 physically active individuals.19 The scatterplot below shows the relationship between height and shoulder girth (over deltoid muscles), both measured in centimeters.

\begin{center}
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# load packages -----------------------------------------------------
library(openintro)
# load data ---------------------------------------------------------
data(bdims)
# plot height vs. shoulder girth ------------------------------------
par(mar = c(3.8, 3.8, 0.5, 0.5), las = 1, mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.25, cex.axis = 1.25)
plot(bdims$hgt ~ bdims$sho.gi, 
     xlab = "Shoulder girth (cm)", ylab = "Height (cm)", 
     pch = 19, col = COL[1,2])
```
\end{center}

(a) Describe the relationship between shoulder girth and height.

  _The relationship seems to be linear_

(b) How would the relationship change if shoulder girth was measured in inches while the units of height remained in centimeters?

  _It should remain the same; however the points  will be more  squished to the left_


--------------------------------------------------------------------------------

\clearpage
                                      
**Body measurements, Part III.** (8.24, p. 326) Exercise above introduces data on shoulder girth and height of a group of individuals. The mean shoulder girth is 107.20 cm with a standard deviation of 10.37 cm. The mean height is 171.14 cm with a standard deviation of 9.41 cm. The correlation between height and shoulder girth is 0.67.

(a) Write the equation of the regression line for predicting height.

$\widehat{ x } =\quad 107.2\\ \bar{ y } =\quad 171.14\\ { s }_{ \bar{ x }  }=\quad 10.37\\ { s }_{ \bar{ y }  }=\quad 9.41\\ { R } =\quad 0.67$
  $b1\quad =\quad \frac { { s }_{ \bar{ y }  } }{ { s }_{ \bar{ x }  } } *{ R }$
  $b1\quad =\quad \frac { 9.41 }{ 10.37 } *\quad 0.67$
  $(y-\bar{ y } )\quad =\quad b1(x-\bar{ x } )$
  $(y-171.14)\quad =\quad 6.9479*(x-107.2)$

_The equation of regression will be:_

  $y\quad =\quad 105.965\quad +\quad 0.607*x$
  $height\quad =\quad 105.965\quad +\quad 0.607*shoulder\quad girth$


(b) Interpret the slope and the intercept in this context.

_The slope is: 0.607 means that to increase height, the  shoulder length should be increased by this slope which is 0.607_
_The intercept: for a shoulder girth of 0 cm, the average height increases by 105.965 cm_

(c) Calculate $R^2$ of the regression line for predicting height from shoulder girth, and interpret it in the context of the application.


${ { R } }^{ 2 }\quad =\quad { 0.67 }^{ 2 }\\ { { R } }^{ 2 }\quad =\quad 0.4489$


_44.89% of the variation in height is explained by shoulder girth_

(d) A randomly selected student from your class has a shoulder girth of 100 cm. Predict the height of this student using the model.


$height\quad =\quad 105.965\quad +\quad 0.607*100$
$height\quad =\quad 166.762$

_The height should be 166.76_

(e) The student from part (d) is 160 cm tall. Calculate the residual, and explain what this residual means.


${ e }_{ i }\quad =\quad { y }_{ i }-\bar{ y } \\ { e }_{ i }\quad =\quad 160\quad -\quad 166.76\\ { e }_{ i }\quad =\quad -6.76$

_This means by a negative sign that the model overestimated the height by 6.76_

(f) A one year old has a shoulder girth of 56 cm. Would it be appropriate to use this linear model to predict the height of this child?

_the average shoulder girth for this sample is 107.2 which means that 56 point will be far  away. So I think that we cannot use this  model to  predict such prediction_






--------------------------------------------------------------------------------

\clearpage

**Cats, Part I.** (8.26, p. 327) The following regression output is for predicting the heart weight (in g) of cats from their body weight (in kg). The coefficients are estimated using a dataset of 144 domestic cats.

\begin{center}
{
\begin{tabular}{rrrrr}
    \hline
            & Estimate  & Std. Error    & t value   & Pr($>$$|$t$|$) \\ 
    \hline
(Intercept) & -0.357    & 0.692         & -0.515    & 0.607 \\ 
body wt     & 4.034     & 0.250         & 16.119    & 0.000 \\ 
    \hline
\end{tabular} \ \\
$s = 1.452 \qquad R^2 = 64.66\% \qquad R^2_{adj} = 64.41\%$ 
}
\end{center}

\begin{center}
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# load packages -----------------------------------------------------
library(openintro)
library(xtable)
library(MASS)
# load data ---------------------------------------------------------
data(cats)
# model heart weight vs. weight -------------------------------------
m_cats_hwt_bwt <- lm(cats$Hwt ~ cats$Bwt)
# plot heart weight vs. weight --------------------------------------
par(mar = c(3.7, 3.7, 0.5, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
plot(cats$Hwt ~ cats$Bwt, 
     xlab = "Body weight (kg)", ylab = "Heart weight (g)", 
     pch = 19, col = COL[1,2],
     xlim = c(2,4), ylim = c(5, 20.5), axes = FALSE)
axis(1, at = seq(2, 4, 0.5))
axis(2, at = seq(5, 20, 5))
box()
```
\end{center}

(a) Write out the linear model.

_heart_weight = -0.357 + 4.034 * body_weight _

(b) Interpret the intercept.

_Intercept means that for body weight 0, the average heart weight is -0.357 grams_

(c) Interpret the slope.

_The slope means  that to increase heart_weight ,  the body weight should be increased by 4.035_

(d) Interpret $R^2$.

_64% R-squared means that the variablility in heart weight of cats can be explained by body_weight_

(e) Calculate the correlation coefficient.

```{r}
R <- sqrt(0.6466)
R
```



--------------------------------------------------------------------------------

\clearpage

**Rate my professor.** (8.44, p. 340) Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. Researchers at University of Texas, Austin collected data on teaching evaluation score (higher score means better) and standardized beauty score (a score of 0 means average, negative score means below average, and a positive score means above average) for a sample of 463 professors. The scatterplot below shows the relationship between these variables, and also provided is a regression output for predicting teaching evaluation score from beauty score.

\begin{center}
\begin{tabular}{rrrrr}
    \hline
            & Estimate  & Std. Error    & t value   & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & 4.010     & 0.0255        & 	157.21  & 0.0000 \\ 
beauty      &  \fbox{\textcolor{white}{{ Cell 1}}}  
                        & 0.0322        & 4.13      & 0.0000\vspace{0.8mm} \\ 
   \hline
\end{tabular}


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# load packages -----------------------------------------------------
library(openintro)
# load data ---------------------------------------------------------
prof_evals_beauty <- read.csv("https://github.com/jbryer/DATA606Fall2019/raw/master/course_data/prof_evals_beauty.csv")
# rename variables for convenience ----------------------------------
beauty <- prof_evals_beauty$btystdave
eval <- prof_evals_beauty$courseevaluation
# model evaluation scores vs. beauty --------------------------------
m_eval_beauty = lm(eval ~ beauty)
# scatterplot of evaluation scores vs. beauty -----------------------
par(mar = c(3.9, 3.9, 0.5, 0.5), las = 0, mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5, las = 1)
plot(eval ~ beauty, 
     xlab = "Beauty", ylab = "Teaching evaluation", 
     pch = 19, col = COL[1,2], 
     axes = FALSE)
axis(1, at = seq(-1, 2, 1))
axis(2, at = seq(2, 5, 1))
box()
```
\end{center}

(a) Given that the average standardized beauty score is -0.0883 and average teaching evaluation score is 3.9983, calculate the slope. Alternatively, the slope may be computed using just the information provided in the model summary table.

_considered that both x-hat and y-hat both located on the regression line, we can have the following equation of the regression line_

```{r}
slope <- (3.9983 - 4.010)/(-0.0883)
slope
```

(b) Do these data provide convincing evidence that the slope of the relationship between teaching evaluation and beauty is positive? Explain your reasoning.

_Since the slope is positive the relationship is positive. If we set up a hypothesis test with
${ H }_{ 0 }\quad :\quad { \beta  }_{ 1 }\quad =\quad 0\quad and\quad \\ { H }_{ A }\quad :\quad { \beta  }_{ 1 }\quad >\quad 0$, 
then based on the summary table the p−value is nearly 0. And this is for a two-sided test, so it’ll be even closer to 0 for a one-sided test. We reject the null hypothesis. There is convincing evidence that the relationship between teaching evluation and beauty is positive._


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# residuals plot ----------------------------------------------------
par(mar = c(3.9, 3.9, 0.5, 0.5), las = 0, mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5, las = 1)
plot(m_eval_beauty$residuals ~ beauty, 
     xlab = "Beauty", ylab = "Residuals", 
     pch = 19, col = COL[1,2], 
     ylim = c(-1.82, 1.82), axes = FALSE)
axis(1, at = seq(-1, 2, 1))
axis(2, at = seq(-1, 1, 1))
box()
abline(h = 0, lty = 3)
# residuals histogram -----------------------------------------------
par(mar = c(3.9, 3, 0, 0), cex.lab = 1.5, cex.axis = 1.5)
hist(m_eval_beauty$residuals, 
     xlab = "Residuals", ylab = "", main = "",
     col = COL[1],
     xlim = c(-2,2))
# normal probability plot of residuals ------------------------------
par(mar = c(3.9, 3.9, 0.5, 0.5), mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
qqnorm(m_eval_beauty$residuals, 
       pch = 19, col = COL[1,2],
       main = "", las = 0)
qqline(m_eval_beauty$residuals, col = COL[1])
# order of residuals ---------------------------------------------===
par(mar = c(3.9, 3.9, 0.5, 0.5), mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
plot(m_eval_beauty$residuals, 
     xlab = "Order of data collection", ylab = "Residuals", main = "",
     pch = 19, col = COL[1,2],
     ylim = c(-1.82, 1.82), axes = FALSE)
axis(1)
axis(2, at = seq(-1, 1, 1))
box()
abline(h = 0, lty = 3)
```

(c) List the conditions required for linear regression and check if each one is satisfied for this model based on the following diagnostic plots.

_Linearity: Based on the scatterplot, there may be a weak linear relationship. There is no evident pattern in the residual plot. Nearly normal residuals: The histogram of the residuals exhibits a left skew. Additionally, the points seem to move away from the normal probability line on each end. However, the bulk of the data is very close to the line. I would conclude that the distribution of residuals is nearly normal. Constant variability: Based on residual plot, there appears to be constant variability in the data. Independent observations: Observations are not a time series, and can be assumed to be independent (unless there is evidence that students copied each other’s evaluations). I believe all conditions are satisfied for this linear model._




