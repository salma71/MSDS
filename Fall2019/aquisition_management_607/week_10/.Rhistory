final_df <- merge(final_table, opponents, by.x = "State",by.y = "Total", sort = TRUE)
final_df <- merge(final_table, opponents, by = "State", sort = TRUE)
final_df <- merge(final_table, opponents)
final_df
final_df <- final_table[opponents, on = "Pair"]
final_df <- final_table[opponents, on = "pair"]
into <- c("Pair", "Player Name","Total","Round","Round.1","Round.2","Round.3","Round.4","Round.5","Round.6","State","USCF ID / Rtg (Pre>Post)","Pts","1","2", "3","4","5","6", "7")
splitted_df <- separate(new_table, Binded, into, sep = "\\|")
splitted_df
colnames(splitted_df)
clean_df <- splitted_df[-c(1),]
clean_df
colnames(clean_df)
dim(clean_df)
rtg_extract <- str_extract_all(clean_df$`USCF ID / Rtg (Pre>Post)`, "\\b\\d{1,}")
#as.data.frame(rtg_split)
colnames(rtg_extract, do.NULL = FALSE)
#<- c("USCF ID", "Pre", "Post")
rtg_split <- str_split_fixed(rtg_extract, "[[:punct:]]\\s+", 3)
#rtg_split
rtg_df <- data.frame(as.character(str_remove_all(rtg_extract, "[[:punct:],c]")))
rtg_df
is.data.frame(rtg_df)
header_name <- c("USCF ID", "Pre", "Post")
# rename colums
colnames(rtg_df)
names(rtg_df)[names(rtg_df) == "as.character.str_remove_all.rtg_extract......punct...c...."] <- "years"
rtg_df <- separate(rtg_df, years, header_name, sep = " ")
rtg_df
clean_df
colnames(clean_df)
drop_uncleandata <- clean_df[,-c(12)]
drop_uncleandata
tournament_df <- cbind(drop_uncleandata, rtg_df)
tournament_df
colnames(tournament_df)
ordered_tournament_df <- tournament_df[c(1,2,11,3,21,22,12,4,5,6,7,8,9,10,13,14,14,16,17,18,19,20)]
ordered_tournament_df
colnames(ordered_tournament_df)
final_table <- subset(ordered_tournament_df, select = c(1:7))
head(final_table)
#my_var <- c(1,2,3,4,5)
final_table$avg_rtg <- 0
final_table
#tournament_subset
#score table
score_df <- subset(ordered_tournament_df, select = c(1:2))
score_df
#final_table$NGames <- c(0)
#final_table
final_table
final_df <- final_table[opponents, on = "pair"]
final_df <- final_table[opponents, on = "Pair"]
final_df <- merge(final_table, opponents)
final_df
final_df[3, 9]
final_df[0, 9]
final_df[1, 9]
final_df[64, 9]
# Procedure to calculate Average Pre-Rating for each player
for (i in 1:dim(final_df)) {
for (j in 9:15) {
if(final_df[i,j] == final_df$Pair) {
final_df$avg_rtg[i] <- round(as.numeric(final_df$Pre[j]) + as.numeric(final_df$Pre[i]) / as.numerica(final_df$NGames[i]),0)
}
}
}
final_df
final_df$avg_rtg <- 5
final_df
final_df$avg_rtg[1,9] <- 5
final_df$avg_rtg[1,9] <- 10
final_df$avg_rtg[1,9]
final_df$avg_rtg[1]
# Procedure to calculate Average Pre-Rating for each player
for (i in 1:dim(final_df)) {
for (j in 9:15) {
if(final_df[i,j] == final_df$Pair) {
final_df$avg_rtg[i] <- as.numeric(final_df$Pre[j]) + as.numeric(final_df$Pre[i])
}
}
}
final_df
final_df$avg_rtg <- 0
# Procedure to calculate Average Pre-Rating for each player
for (i in 1:dim(final_df)) {
for (j in 9:15) {
if(final_df[i,j] == final_df$Pair) {
final_df$avg_rtg[i] <- as.numeric(final_df$Pre[j]) + as.numeric(final_df$Pre[i])
}
}
}
final_df
# Procedure to calculate Average Pre-Rating for each player
for (i in 1:nrow(final_df)) {
for (j in 9:15) {
if(final_df[i,j] == final_df$Pair) {
final_df$avg_rtg[i] <- as.numeric(final_df$Pre[j]) + as.numeric(final_df$Pre[i])
}
}
}
final_df$avg_rtg
# Procedure to calculate Average Pre-Rating for each player
for (i in 1:nrow(final_df)) {
for (j in 9:15) {
if(final_df[i,j] == final_df$Pair) {
final_df$avg_rtg[i] <- as.numeric(final_df$Pre[j]) + as.numeric(final_df$Pre[i])
}
}
}
final_df
# Procedure to calculate Average Pre-Rating for each player
for (i in 1:nrow(final_df)) {
for (j in 9:15) {
if(final_df[i,j] == final_df$Pair) {
final_df$avg_rtg[i] <- as.numeric(as.character(final_df$Pre[j])) + as.numeric(as.character(final_df$Pre[i]))
}
}
}
final_df
final_df
browser()
i
j
final_df
if(final_df[i,j] == final_df$Pair) {
final_df$avg_rtg[i] <- as.numeric(as.character(final_df$Pre[j])) + as.numeric(as.character(final_df$Pre[i]))
}
final_df
i
j
i+1
i
for (i in 1:nrow(final_df)) {
i
for (i in 1:nrow(final_df)) {
for (i in 1:nrow(final_df)) {
for (i in 1:nrow(final_df)) {
final_df
}
i
}
}
install.packages("rpart")
install.packages("rpart.plot")
knitr::opts_chunk$set(echo = TRUE)
library(R.utils)
library(tidyverse)
library(tidytext)
library(readtext)
library(stringr)
library(tm)
library(rpart)
library(rpart.plot)
base_url_spam <- "https://spamassassin.apache.org/old/publiccorpus/20030228_spam_2.tar.bz2"
spam_zip <- "20030228_spam_2.tar.bz2"
spam_tar <- "20030228_spam_2.tar"
base_url_ham <- "https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2"
ham_zip <- "20030228_easy_ham_2.tar.bz2"
ham_tar <- "20030228_easy_ham_2.tar"
if(!file.exists(spam_tar)){
res_spam <- tryCatch(download.file(base_url_spam,
destfile= spam_folder,
method="curl"),
error=function(e) 1)
bunzip2(spam_zip)
untar(spam_tar, exdir="spam_ham_documents")
}
if(!file.exists(ham_tar)){
res_ham <- tryCatch(download.file(base_url_ham,
destfile= ham_folder,
method="curl"),
error=function(e) 1)
bunzip2(ham_zip)
untar(ham_tar, exdir = "spam_ham_documents")
} else {
paste("The file is already exists!")
}
setwd("~/Desktop/MSDS_2019/Fall2019/aquisition_management_607/week_10")
base_dir <- "/Users/salmaelshahawy/Desktop/MSDS_2019/Fall2019/aquisition_management_607/week_10/spam_ham_documents"
email_content <- NA
get_content <- function(type) {
files_path <- paste(base_dir,type, sep = "/")
files_name <- list.files(files_path)
for (file in 1:length(files_name)) {
file_path <- paste(files_path, files_name[file], sep = "/")
content_per_file <- file_path %>%
lapply(readLines)
email_content <- c(email_content, content_per_file)
}
return(email_content)
}
spam_test <- get_content("spam_2") #list
ham_test <- get_content("easy_ham_2") #list
get_nested_content <- function(list_name) {
nested_value <- NA
for (value in 2:length(list_name)) {
value_per_row <- list_name[[value]]
nested_value <- c(nested_value, value_per_row)
}
return(nested_value)
}
spam_content <- get_nested_content(spam_test)
ham_content <- get_nested_content(ham_test)
spam_df <- as.data.frame(spam_content) %>%
mutate(class = "spam") %>% #adding a class tag
na.omit(spam_df)
names(spam_df) <- c("text", "class")
spam_df
ham_df <- as.data.frame(ham_content) %>%
mutate(class = "ham") %>% #adding a class tag
na.omit(ham_df)
names(ham_df) <- c("text", "class")
ham_df
data_df <- rbind(spam_df, ham_df) %>%
mutate_all(funs(gsub("[^[:alnum:][:blank:]+\\s+?&-]", "",.)))
data_df
table(data_df$class)
corpus_data = VCorpus(VectorSource(data_df$text))
corpus_data = tm_map(corpus_data, content_transformer(stringi::stri_trans_tolower))
corpus_data = tm_map(corpus_data, removeNumbers)
corpus_data = tm_map(corpus_data, removePunctuation)
corpus_data = tm_map(corpus_data, stripWhitespace)
corpus_data = tm_map(corpus_data, removeWords, stopwords("english"))
corpus_data = tm_map(corpus_data, stemDocument)
#as.character(corpus[[1]])
dtm <- DocumentTermMatrix(corpus_data)
dtm
dtm = removeSparseTerms(dtm, 0.999)
dim(dtm)
inspect(dtm[40:50, 10:15])
# Remove sparse terms (that don't appear very often)
spdtm = removeSparseTerms(dtm, 0.99)
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
# make variable names of emailsSparse valid i.e. R-friendly (to convert variables names starting with numbers)
colnames(emailsSparse) = make.names(colnames(emailsSparse))
# word stem that shows up most frequently across all the emails:
sort(colSums(emailsSparse))
emailsSparse$spam = as.factor(emailsSparse$spam)
emailsSparse = as.data.frame(as.matrix(spdtm))
# make variable names of emailsSparse valid i.e. R-friendly (to convert variables names starting with numbers)
colnames(emailsSparse) = make.names(colnames(emailsSparse))
# word stem that shows up most frequently across all the emails:
sort(colSums(emailsSparse))
# Add dependent variable to this dataset
emailsSparse$spam = emails$spam
emailsSparse = as.data.frame(as.matrix(spdtm))
# make variable names of emailsSparse valid i.e. R-friendly (to convert variables names starting with numbers)
colnames(emailsSparse) = make.names(colnames(emailsSparse))
# word stem that shows up most frequently across all the emails:
sort(colSums(emailsSparse))
# Add dependent variable to this dataset
emailsSparse$spam = email$spam
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
y
}
# Apply the convert_count function to get final training and testing DTMs
datasetNB <- apply(dtm, 2, convert_count)
dtm = removeSparseTerms(dtm, 0.999)
dim(dtm)
dtm = removeSparseTerms(dtm, 0.999)
dtm
View(dtm)
dtm[["dimnames"]][["Terms"]]
dtm = removeSparseTerms(dtm, 0.999)
dtm
freq <- colSums(as.matrix(dtm))
dtm = removeSparseTerms(dtm, 0.999)
dtm
freq <- colSums(as.matrix(dtm))
freq
sp = VCorpus(VectorSource(data_df))
View(sp)
sp[["1"]][["content"]]
dtm = removeSparseTerms(dtm, 0.999)
dtm
freq<- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
tail(freq, 10)
findFreqTerms(dtm, lowfreq=60)
wf<- data.frame(word=names(freq), freq=freq)
head(wf)
wf<- data.frame(word=names(freq), freq=freq)
head(wf)
pp <- ggplot(subset(wf, freq>100), aes(x=reorder(word, -freq), y =freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
pp
findFreqTerms(dtm, lowfreq=100)
wf<- data.frame(word=names(freq), freq=freq)
head(wf)
pp <- ggplot(subset(wf, freq>100), aes(x=reorder(word, -freq), y =freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
pp
wf<- data.frame(word=names(freq), freq=freq)
head(wf)
pp <- ggplot(subset(wf, freq>500), aes(x=reorder(word, -freq), y =freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
pp
wf<- data.frame(word=names(freq), freq=freq)
head(wf)
mean(wf)
pp <- ggplot(subset(wf, freq>500), aes(x=reorder(word, -freq), y =freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
pp
wf<- data.frame(word=names(freq), freq=freq)
head(wf)
mean(wf$freq)
pp <- ggplot(subset(wf, freq>500), aes(x=reorder(word, -freq), y =freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
pp
wf<- data.frame(word=names(freq), freq=freq)
head(wf)
mean(wf$freq)
pp <- ggplot(subset(wf, freq>1000), aes(x=reorder(word, -freq), y =freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
pp
wf<- data.frame(word=names(freq), freq=freq)
head(wf)
mean(wf$freq)
pp <- ggplot(subset(wf, freq>1200), aes(x=reorder(word, -freq), y =freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
pp
to_corpus <- function(df, type) {
corpus_name <- VCorpus(VectorSource(df)) %>%
add_tag(tag = "document type", value = type)
return(corpus_name)
}
spam_corpus <- to_corpus(spam_test,"spam")
spam_corpus <- to_corpus(spam_df,"spam")
to_corpus <- function(df, type) {
corpus_name <- VCorpus(VectorSource(df)) %>%
add_tag(tag = "document type", value = type)
return(corpus_name)
}
```{r}
to_corpus <- function(df, type) {
corpus_name <- VCorpus(VectorSource(df)) %>%
add_tag(tag = "document type", value = type)
return(corpus_name)
}
add_tag <- function(corpus, tag, value){
for (i in 1:length(corpus)){
meta(corpus[[i]], tag) <- value                    # Add the value to the specified tag
}
return(corpus)
}
to_corpus <- function(df, type) {
corpus_name <- VCorpus(VectorSource(df)) %>%
add_tag(tag = "document type", value = type)
return(corpus_name)
}
add_tag <- function(corpus, tag, value){
for (i in 1:length(corpus)){
meta(corpus[[i]], tag) <- value                    # Add the value to the specified tag
}
return(corpus)
}
spam_corpus <- to_corpus(spam_df,"spam")
#summary(spam_corpus)
#str(spam_corpus)
ham_corpus <- to_corpus(ham_df, "ham")
#summary(ham_corpus)
get_clean <- function(corpus_name){
corpus_name <- corpus_name %>%
tm_map(removeNumbers) %>%                       # Remove numbers
tm_map(removePunctuation) %>%                   # Remove punctuation symbols
tm_map(stringi::stri_trans_tolower) %>%         # Transform  to lowercase
tm_map(PlainTextDocument) %>%                   # Transform back to PlainTextDocument
tm_map(removeWords, stopwords("en")) %>%        # Remove stopwords
tm_map(stripWhitespace) %>%                     # Remove white spaces
tm_map(stemDocument)                            #Reduce to stems
return(corpus_name)
}
#as.character(corpus[[1]])
to_corpus <- function(df, type) {
corpus_name <- VCorpus(VectorSource(df)) %>%
add_tag(tag = "document type", value = type)
return(corpus_name)
}
add_tag <- function(corpus, tag, value){
for (i in 1:length(corpus)){
meta(corpus[[i]], tag) <- value                    # Add the value to the specified tag
}
return(corpus)
}
get_clean <- function(corpus_name){
corpus_name <- corpus_name %>%
tm_map(removeNumbers) %>%                       # Remove numbers
tm_map(removePunctuation) %>%                   # Remove punctuation symbols
tm_map(stringi::stri_trans_tolower) %>%         # Transform  to lowercase
tm_map(PlainTextDocument) %>%                   # Transform back to PlainTextDocument
tm_map(removeWords, stopwords("en")) %>%        # Remove stopwords
tm_map(stripWhitespace) %>%                     # Remove white spaces
tm_map(stemDocument)                            #Reduce to stems
return(corpus_name)
}
to_corpus <- function(df, type) {
corpus_name <- VCorpus(VectorSource(df)) %>%
get_clean() %>%
add_tag(tag = "document type", value = type) %>%
return(corpus_name)
}
add_tag <- function(corpus, tag, value){
for (i in 1:length(corpus)){
meta(corpus[[i]], tag) <- value                    # Add the value to the specified tag
}
return(corpus)
}
get_clean <- function(corpus_name){
corpus_name <- corpus_name %>%
tm_map(removeNumbers) %>%                       # Remove numbers
tm_map(removePunctuation) %>%                   # Remove punctuation symbols
tm_map(stringi::stri_trans_tolower) %>%         # Transform  to lowercase
tm_map(PlainTextDocument) %>%                   # Transform back to PlainTextDocument
tm_map(removeWords, stopwords("en")) %>%        # Remove stopwords
tm_map(stripWhitespace) %>%                     # Remove white spaces
tm_map(stemDocument)                            #Reduce to stems
return(corpus_name)
}
spam_corpus <- to_corpus(spam_df,"spam")
to_corpus <- function(df, type) {
corpus_name <- VCorpus(VectorSource(df)) %>%
get_clean() %>%
add_tag(tag = "document type", value = type) %>%
return(corpus_name)
}
add_tag <- function(corpus, tag, value){
for (i in 1:length(corpus)){
meta(corpus[[i]], tag) <- value                    # Add the value to the specified tag
}
return(corpus)
}
get_clean <- function(corpus_name){
corpus_name <- corpus_name %>%
tm_map(removeNumbers) %>%                       # Remove numbers
tm_map(removePunctuation) %>%                   # Remove punctuation symbols
tm_map(stringi::stri_trans_tolower) %>%         # Transform  to lowercase
tm_map(PlainTextDocument) %>%                   # Transform back to PlainTextDocument
tm_map(stripWhitespace) %>%                     # Remove white spaces
tm_map(stemDocument) %>%                            #Reduce to stems
tm_map(removeWords, stopwords('english'))        # Remove stopwords
return(corpus_name)
}
spam_corpus <- to_corpus(spam_df,"spam")
table(data_df$class)
spam_corpus <- to_corpus(spam_df,"spam")
corpus_data = VCorpus(VectorSource(data_df$text))
corpus_data = tm_map(corpus_data, content_transformer(stringi::stri_trans_tolower))
corpus_data = tm_map(corpus_data, removeNumbers)
corpus_data = tm_map(corpus_data, removePunctuation)
corpus_data = tm_map(corpus_data, stripWhitespace)
corpus_data = tm_map(corpus_data, removeWords, stopwords("english"))
corpus_data = tm_map(corpus_data, stemDocument)
#as.character(corpus[[1]])
data_df$class <- as.factor(data_df$class)
corpus_data = VCorpus(VectorSource(data_df$text))
inspect(corpus_data[1:3])
#we need our data in a one-row-per-document format. That is, a document-term matrix.
dtm <- DocumentTermMatrix(corpus_data)
dtm
## 75% of the sample size
smp_size <- floor(0.75 * nrow(data_df))
## set the seed to make your partition reproducible
set.seed(200)
train_ind <- sample(seq_len(nrow(data_df)), size = smp_size)
df.train <- data_df[train_ind, ]
df.test <- data_df[-train_ind, ]
dtm.train <- dtm[train_ind, ]
dtm.test <- dtm[-train_ind, ]
corpus_data.train <- corpus_data[train_ind, ]
## 75% of the sample size
smp_size <- floor(0.75 * nrow(data_df))
## set the seed to make your partition reproducible
set.seed(200)
train_ind <- sample(seq_len(nrow(data_df)), size = smp_size)
df.train <- data_df[train_ind, ]
df.test <- data_df[-train_ind, ]
dtm.train <- dtm[train_ind, ]
dtm.test <- dtm[-train_ind, ]
corpus_data.train <- corpus_data[train_ind, ]
View(corpus_data)
## 75% of the sample size
smp_size <- floor(0.75 * nrow(data_df))
## set the seed to make your partition reproducible
set.seed(200)
train_ind <- sample(seq_len(nrow(data_df)), size = smp_size)
df.train <- data_df[train_ind, ]
df.test <- data_df[-train_ind, ]
dtm.train <- dtm[train_ind, ]
dtm.test <- dtm[-train_ind, ]
corpus_data.train <- corpus_data[1: 250000]
corpus_data.test <- corpus_data[251000:331773]
dim(dtm.train)
fivefreq <- findFreqTerms(dtm.train, 5)
length((fivefreq))
## [1] 12144
# Use only 5 most frequent words (fivefreq) to build the DTM
dtm.train.nb <- DocumentTermMatrix(corpus_doc.train, control=list(dictionary = fivefreq))
fivefreq <- findFreqTerms(dtm.train, 5)
length((fivefreq))
## [1] 12144
# Use only 5 most frequent words (fivefreq) to build the DTM
dtm.train.nb <- DocumentTermMatrix(corpus_data.train, control=list(dictionary = fivefreq))
