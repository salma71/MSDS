View(spam_corpus)
View(spam_test)
library(R.utils)
library(tidyverse)
library(tidytext)
library(readtext)
library(stringr)
library(tm)
base_url_spam <- "https://spamassassin.apache.org/old/publiccorpus/20030228_spam_2.tar.bz2"
spam_zip <- "20030228_spam_2.tar.bz2"
spam_tar <- "20030228_spam_2.tar"
base_url_ham <- "https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2"
ham_zip <- "20030228_easy_ham_2.tar.bz2"
ham_tar <- "20030228_easy_ham_2.tar"
if(!file.exists(spam_tar)){
res_spam <- tryCatch(download.file(base_url_spam,
destfile= spam_folder,
method="auto"),
error=function(e) 1)
bunzip2(spam_zip)
untar(spam_tar, exdir="spam_ham_documents")
}
if(!file.exists(ham_tar)){
res_ham <- tryCatch(download.file(base_url_ham,
destfile= ham_folder,
method="auto"),
error=function(e) 1)
bunzip2(ham_zip)
untar(ham_tar, exdir = "spam_ham_documents")
} else {
paste("The file is already exists!")
}
base_dir <- "/Users/salmaelshahawy/Desktop/MSDS_2019/Fall2019/aquisition_management_607/week_10/spam_ham_documents"
email_content <- NA
get_content <- function(type) {
files_path <- paste(base_dir,type, sep = "/")
files_name <- list.files(files_path)
for (file in 1:length(files_name)) {
file_path <- paste(files_path, files_name[file], sep = "/")
content_per_file <- file_path %>%
lapply(readLines)
email_content <- c(email_content, content_per_file)
}
return(email_content)
}
spam_test <- get_content("spam_2") #list
ham_test <- get_content("easy_ham_2") #list
add_tag <- function(corpus, tag, value){
for (i in 1:length(corpus)){
meta(corpus[[i]], tag) <- value                    # Add the value to the specified tag
}
return(corpus)
}
to_corpus <- function(doc, type) {
corpus_name <- VCorpus(VectorSource(doc)) %>%
add_tag(tag = "document type", value = type)
return(corpus_name)
}
spam_corpus <- to_corpus(spam_test,"spam")
#summary(spam_corpus)
#str(spam_corpus)
ham_corpus <- to_corpus(ham_test, "ham")
#summary(ham_corpus)
View(spam_corpus)
get_clean <- function(corpus_name){
cleaned_corpus <- corpus_name %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(stringi::stri_trans_tolower)) %>%
tm_map(PlainTextDocument)
return(cleaned_corpus)
}
cleaned_spam <- get_clean(spam_corpus)
View(cleaned_spam)
spam_corpus
inspect(spam_corpus[4])
spam_corpus[["5"]]
get_clean <- function(corpus_name){
for (i in 1:length(corpus_name)) {
cleaned_corpus <- corpus_name[[i]] %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(stringi::stri_trans_tolower)) %>%
tm_map(PlainTextDocument)
}
return(cleaned_corpus)
}
cleaned_spam <- get_clean(spam_corpus)
inspect(spam_corpus[[5]])
myCorpus <- spam_corpus[[5]]
myCorpus <- tm_map(myCorpus, removeWords, stopwords('english'))
myCorpus <- myCorpus, removeWords, stopwords('english')
myCorpus %>% removePunctuation
myCorpus
View(myCorpus)
myCorpus[["content"]]
myCorpus <- spam_corpus
View(myCorpus)
myCorpus <- tm_map(myCorpus, removeWords, stopwords('english'))
myCorpus <- tm_map(myCorpus, removePunctuation)
View(myCorpus)
myCorpus[["5"]][["content"]]
myCorpus <- tm_map(content_transformer(stringi::stri_trans_tolower))
myCorpus <- tm_map(myCorpus, content_transformer(stringi::stri_trans_tolower))
View(myCorpus)
myCorpus[["5"]][["content"]]
myCorpus <- tm_map(myCorpus, removeNumbers)
View(myCorpus)
myCorpus[["5"]][["content"]]
myCorpus <- tm_map(myCorpus, removeWords, stopwords('english'))
myCorpus <- tm_map(myCorpus, PlainTextDocument)
View(myCorpus)
get.file.extension("/Users/salmaelshahawy/Desktop/MSDS_2019/Fall2019/aquisition_management_607/week_10/spam_ham_documents/spam_2/00002.9438920e9a55591b18e60d1ed37d992b")
b_dir <- "/Users/salmaelshahawy/Desktop/MSDS_2019/Fall2019/aquisition_management_607/week_10/spam_ham_documents/spam_2"
filz <- list.files(b_dir)
head(filz)
sapply(filez,FUN=function(eachPath){
file.rename(from=eachPath,to=sub(pattern="00001.317e78fa8ee2f54cd4890fdc09ba8176",replacement="new",eachPath))
})
sapply(filz,FUN=function(eachPath){
file.rename(from=eachPath,to=sub(pattern="00001.317e78fa8ee2f54cd4890fdc09ba8176",replacement="new",eachPath))
})
filz <- list.files(pattern="*.a6f26937625654510b0e5442d24f0e46")
filz
filz <- list.files(pattern="*.[[:digit:]]|[[:alpha:]]")
filz
filz <- list.files(b_dir, pattern="*.[[:digit:]]|[[:alpha:]]")
newfiles <- gsub(".[[:digit:]]|[[:alpha:]]$", ".txt", filz)
head(newfiles)
filz <- getFilename(b_dir)
getExtension <- function(file){
ex <- strsplit(basename(file), split="\\.")[[1]]
return(ex[-1])
}
ext <- getExtension("01003.d15cfb579697f595c4aff7197433cd72")
ext
setwd("~/Desktop")
knitr::opts_chunk$set(echo = TRUE)
url.spam <- "http://spamassassin.apache.org/old/publiccorpus/20050311_spam_2.tar.bz2"
file.spam <- "20050311_spam_2.tar.bz2"
file.spam2<-"20050311_spam_2.tar"
url.ham <- "http://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham.tar.bz2"
file.ham <- "20030228_easy_ham.tar.bz2"
file.ham2 <- "20030228_easy_ham.tar"
download.file(url.spam, destfile= file.spam)
download.file(url.ham, destfile=file.ham)
bunzip2(file.spam)
bunzip2(file.ham)
untar(file.ham2, exdir="spamham")
untar(file.spam2, exdir = "spamham")
#Adding files to list
spam.dir="spamham\\spam_2\\"
ham.dir="spamham\\easy_ham\\"
spam.docs=list.files(spam.dir)
ham.docs=list.files(ham.dir)
#Adding files to list
spam.dir="spamham\\spam_2\\"
ham.dir="spamham\\easy_ham\\"
spam.docs=list.files(spam.dir)
ham.docs=list.files(ham.dir)
#Removing the .cmds files in all the folders.
spam.docs = spam.docs[which(spam.docs!="cmds")]
ham.docs=ham.docs[which(ham.docs!="cmds")]
toVCorpus <- function(file_path) {
corpus <- file_path %>%
paste(., list.files(.), sep = "/") %>%          # Create a vector of file paths
lapply(readLines) %>%                           # Read the text in each file
VectorSource() %>%                              # Turn into VectorSource
VCorpus()                                       # Turn into VCorpus
return(corpus)
}
docClean <- function(corpus) {
corpus <- corpus %>%
tm_map(removeNumbers) %>%                       # Remove numbers
tm_map(removePunctuation) %>%                   # Remove punctuation symbols
tm_map(tolower) %>%                             # Transform  to lowercase
tm_map(PlainTextDocument) %>%                   # Transform back to PlainTextDocument
tm_map(removeWords, stopwords("en")) %>%        # Remove stopwords
tm_map(stripWhitespace) %>%                     # Remove white spaces
tm_map(stemDocument)                            #Reduce to stems
return(corpus)
}
addTag <- function(corpus, tag, value){
for (i in 1:length(corpus)){
meta(corpus[[i]], tag) <- value                    # Add the value to the specified tag
}
return(corpus)
}
# Create ham corpus
ham_corpus <- ham.dir%>%
toVCorpus %>%
docClean  %>%
addTag(tag = "ham_spam", value = "ham")
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip"
if (!file.exists("smsspamcollection.zip"))
{
download.file(url=url, destfile="smsspamcollection.zip", method="curl")
}
unzip("smsspamcollection.zip")
data_text <- read.delim("SMSSpamCollection", sep="\t", header=F, colClasses="character", quote="")
str(data_text)
head(data_text)
url <- "https://spamassassin.apache.org/old/publiccorpus/20030228_spam_2.tar.bz2"
if (!file.exists("20030228_spam_2.tar.bz2"))
{
download.file(url=url, destfile="20030228_spam_2.tar.bz2", method="curl")
}
unzip("20030228_spam_2.tar.bz2")
untar("20030228_spam_2.tar")
data_text <- read.delim("20030228_spam_2", sep="\t", header=F, colClasses="character", quote="")
base_url_spam <- "https://spamassassin.apache.org/old/publiccorpus/20030228_spam_2.tar.bz2"
spam_zip <- "20030228_spam_2.tar.bz2"
spam_tar <- "20030228_spam_2.tar"
base_url_ham <- "https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2"
ham_zip <- "20030228_easy_ham_2.tar.bz2"
ham_tar <- "20030228_easy_ham_2.tar"
if(!file.exists(spam_tar)){
res_spam <- tryCatch(download.file(base_url_spam,
destfile= spam_folder,
method="curl"),
error=function(e) 1)
bunzip2(spam_zip)
untar(spam_tar, exdir="spam_ham_documents")
}
if(!file.exists(ham_tar)){
res_ham <- tryCatch(download.file(base_url_ham,
destfile= ham_folder,
method="curl"),
error=function(e) 1)
bunzip2(ham_zip)
untar(ham_tar, exdir = "spam_ham_documents")
} else {
paste("The file is already exists!")
}
setwd("~/Desktop/MSDS_2019/Fall2019/aquisition_management_607/week_10")
spam_test
View(spam_test)
spam_test[[2]]
dim(spam_test)
length(spam_test)
colnames(spam_test)
space <- NA
space <- data.frame(stringsAsFactors = FALSE)
space <- rbind(space, spam_test[[2]])
View(space)
space <- data.frame(stringsAsFactors = FALSE)
space <- cbind(space, spam_test[[2]])
space <- NA
space <- c(space, spam_test[[2]])
space <- NA
filz <- spam_test[[2]]
space <- c(space, filz)
View(space)
space <- c(space, spam_test[[3]])
get_nested_content <- function(list_name) {
nested_value <- NA
for (value in 2:length(list_name)) {
value_per_row <- list_name[[value]] %>%
lapply(readLines)
nested_value <- c(nested_value, value_per_row)
}
return(nested_value)
}
yes <- get_nested_content(spam_test)
get_nested_content <- function(list_name) {
nested_value <- NA
for (value in 2:length(list_name)) {
value_per_row <- list_name[[value]]
nested_value <- c(nested_value, value_per_row)
}
return(nested_value)
}
get_nested_content <- function(list_name) {
nested_value <- NA
for (value in 2:length(list_name)) {
value_per_row <- list_name[[value]]
nested_value <- c(nested_value, value_per_row)
}
return(nested_value)
}
yes <- get_nested_content(spam_test)
View(yes)
spam_content <- get_nested_content(spam_test)
ham_content <- get_nested_content(ham_test)
make_df <- function(list_name, type) {
df <- data.frame(stringsAsFactors = FALSE)
for (i in 1:length(list_name)) {
df <- rbind(df, list_name[[i]]) %>%
mutate(class = type)
names(df)[1] <- "texts"
}
spam_df <- make_df(spam_test, "spam")
ham_df <- make_df(ham_test, "ham")
spam_df
ham_df
spam_content <- get_nested_content(spam_test)
ham_content <- get_nested_content(ham_test)
make_df <- function(list_name, type) {
df <- data.frame(stringsAsFactors = FALSE)
for (i in 2:length(list_name)) {
df <- cbind(df, list_name[[i]]) %>%
mutate(class = type)
names(df)[1] <- "texts"
}
spam_df <- make_df(spam_test, "spam")
get_nested_content <- function(list_name) {
nested_value <- NA
for (value in 2:length(list_name)) {
value_per_row <- list_name[[value]]
nested_value <- c(nested_value, value_per_row)
}
return(nested_value)
}
spam_content <- get_nested_content(spam_test)
ham_content <- get_nested_content(ham_test)
make_df <- function(list_name, type) {
df <- data.frame(stringsAsFactors = FALSE)
for (i in 2:length(list_name)) {
df <- cbind(df, list_name[[i]]) %>%
mutate(class = type)
names(df)[1] <- "texts"
}
spam_df <- make_df(spam_content, "spam")
make_df <- function(list_name, type) {
df <- data.frame(check.names = TRUE, stringsAsFactors = FALSE)
for (i in 2:length(list_name)) {
df <- cbind(df, list_name[[i]]) %>%
mutate(class = type)
names(df)[1] <- "texts"
}
spam_df <- make_df(spam_content, "spam")
View(spam_df)
make_df <- function(list_name, type) {
df <- data.frame(check.names = TRUE, stringsAsFactors = FALSE)
for (i in 2:length(list_name)) {
df <- cbind(df, list_name[[i]]) %>%
mutate(class = type)
names(df)[1] <- "texts"
}
spam_df <- make_df(spam_content, "spam")
View(spam_content)
typeof
typeof(spam_content)
out <- read.table(text = spam_content, sep=",", fill = TRUE,
header = TRUE, stringsAsFactors = FALSE)
out
View(out)
typeof(out)
data.table::fread(ham_content)
read.table(text=ham_content,col.names=c('text'))
out <- read.table(ham_content)
read.table(text=ham_content,col.names=c('texts'))
out <- data.frame(lapply(ham_content, type.convert), stringsAsFactors=FALSE)
out <- data.frame(as.list(testVect))
out <- data.frame(as.list(ham_content))
View(out)
typeof(out)
ham_content[3]
ham_content
make_df <- function(list_name, type) {
df <- data.frame(stringsAsFactors = FALSE)
for (i in 2:length(list_name)) {
df <- rbind(df, list_name) %>%
mutate(class = type)
names(df)[1] <- "texts"
}
spam_df <- make_df(spam_content, "spam")
make_df <- function(list_name, type) {
df <- data.frame(stringsAsFactors = FALSE)
for (i in 2:length(list_name)) {
df <- rbind(df, list_name) %>%
mutate(class = type)
names(df)[1] <- "texts"
}
spam_df <- make_df(spam_content, "spam")
make_df <- function(list_name, type) {
df <- data.frame(stringsAsFactors = FALSE)
df <- rbind(df, list_name) %>%
mutate(class = type)
names(df)[1] <- "texts"
}
make_df <- function(list_name, type) {
df <- data.frame(stringsAsFactors = FALSE)
df <- rbind(df, list_name) %>%
mutate(class = type)
names(df)[1] <- "texts"
}
spam_df <- make_df(spam_content, "spam")
df <- data.frame(stringsAsFactors = FALSE)
df <- rbind(df, spam_content)
View(df)
df <- data.frame(stringsAsFactors = FALSE)
df <- cbind(df, spam_content)
as.data.frame(spam_content)
test <-as.data.frame(spam_content)
View(test)
typeof(test)
class(ttest)
class(test)
spam_df <- as.data.frame(spam_content) %>%
mutate(class = "spam")
spam_df
spam_df <- as.data.frame(spam_content) %>%
mutate(class = "spam")
spam_df <- spam_df[-1,]
spam_df
spam_df <- as.data.frame(spam_content) %>%
mutate(class = "spam")  #adding a class tag
spam_df
spam_df <- as.data.frame(spam_content) %>%
mutate(class = "spam") %>% #adding a class tag
na.omit(spam_df)
spam_df
ham_df <- as.data.frame(ham_content) %>%
mutate(class = "ham") %>% #adding a class tag
na.omit(ham_df)
spam_df
ham_df <- as.data.frame(ham_content) %>%
mutate(class = "ham") %>% #adding a class tag
na.omit(ham_df)
ham_df
spam_df <- as.data.frame(spam_content) %>%
mutate(class = "spam") %>% #adding a class tag
na.omit(spam_df)
spam_df
data_df <- rbind(spam_df, ham_df)
data_df <- cbind(spam_df, ham_df)
ham_df <- as.data.frame(ham_content) %>%
mutate(class = "ham") %>% #adding a class tag
na.omit(ham_df)
names(ham_df) <- c("text", "class")
ham_df
spam_df <- as.data.frame(spam_content) %>%
mutate(class = "spam") %>% #adding a class tag
na.omit(spam_df)
names(spam_df) <- c("text", "class")
spam_df
data_df <- rbind(spam_df, ham_df)
data_df
table(data_df$class)
corpus_data = VCorpus(VectorSource(data_df$text))
as.character(corpus[[1]])
corpus_data = VCorpus(VectorSource(data_df$text))
#as.character(corpus_data[[1]])
View(corpus_data)
as.character(corpus_data[[1]])
corpus_data = VCorpus(VectorSource(data_df$text))
corpus_data = tm_map(corpus_data, content_transformer(tolower))
corpus_data = tm_map(corpus_data, content_transformer(stringi::stri_trans_tolower))
corpus_data = tm_map(corpus_data, removeNumbers)
corpus_data = tm_map(corpus_data, removePunctuation)
corpus_data = tm_map(corpus_data, removeWords, stopwords("english"))
corpus_data = tm_map(corpus_data, content_transformer(stringi::stri_trans_tolower))
corpus_data = tm_map(corpus_data, removeNumbers)
corpus_data = tm_map(corpus_data, removePunctuation)
corpus_data = tm_map(corpus_data, stemDocument)
corpus_data = tm_map(corpus_data, stripWhitespace)
#as.character(corpus[[1]])
corpus_data = tm_map(corpus_data, content_transformer(stringi::stri_trans_tolower))
corpus_data = tm_map(corpus_data, removeNumbers)
corpus_data = tm_map(corpus_data, removePunctuation)
corpus_data = tm_map(corpus_data, stemDocument)
corpus_data = tm_map(corpus_data, stripWhitespace)
corpus_data = tm_map(corpus_data, removeWords, stopwords("english"))
as.character(corpus_data[[1]])
corpus_data = tm_map(corpus_data, content_transformer(stringi::stri_trans_tolower))
corpus_data = tm_map(corpus_data, removeNumbers)
corpus_data = tm_map(corpus_data, removePunctuation)
#corpus_data = tm_map(corpus_data, stemDocument)
corpus_data = tm_map(corpus_data, stripWhitespace)
#corpus_data = tm_map(corpus_data, removeWords, stopwords("english"))
#as.character(corpus[[1]])
as.character(corpus_data[[1]])
corpus_data = tm_map(corpus_data, PlainTextDocument)
as.character(corpus_data[[1]])
dtm <- DocumentTermMatrix(corpus_data)
df <- data_df
dfa <- gsub("[[:punct:]]", "", df$text)
View(dfa)
data_df <- rbind(spam_df, ham_df) %>%
mutate_all(funs(gsub("[^[:alnum:][:blank:]+?&/\\-]", "", .)))
data_df
View(data_df)
data_df <- rbind(spam_df, ham_df) %>%
mutate_all(funs(gsub("[^[[:alnum:]][[:blank:]]+?&/\\-]", "", .)))
data_df
data_df <- rbind(spam_df, ham_df) %>%
mutate_all(funs(gsub("[^[:alnum:][:blank:]+?&/\\-\\S]", "", .)))
data_df
data_df <- rbind(spam_df, ham_df) %>%
mutate_all(funs(gsub("[^[:alnum:][:blank:]+?&-]", "", .)))
data_df
data_df <- rbind(spam_df, ham_df) %>%
mutate_all(funs(gsub("[^[:alnum:][:blank:]+?&-]", "")))
data_df <- rbind(spam_df, ham_df) %>%
mutate_all(funs(gsub("[^[:alnum:][:blank:]+?&-]", "",.)))
data_df
table(data_df$class)
corpus_data = VCorpus(VectorSource(data_df$text))
corpus_data = tm_map(corpus_data, content_transformer(stringi::stri_trans_tolower))
corpus_data = tm_map(corpus_data, removeNumbers)
corpus_data = tm_map(corpus_data, removePunctuation)
#corpus_data = tm_map(corpus_data, stemDocument)
corpus_data = tm_map(corpus_data, stripWhitespace)
#corpus_data = tm_map(corpus_data, removeWords, stopwords("english"))
#as.character(corpus[[1]])
dtm <- DocumentTermMatrix(corpus_data)
dtm
corpus_data = tm_map(corpus_data, removeWords, stopwords("english"))
data_df <- rbind(spam_df, ham_df) %>%
mutate_all(funs(gsub("[^[:alnum:][:blank:]+\\s+?&-]", "",.)))
data_df
